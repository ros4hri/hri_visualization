#!/usr/bin/env python3

import rospy

from hri_msgs.msg import IdsList, Skeleton2D
from sensor_msgs.msg import Image, CompressedImage
from rospkg import RosPack
from pyhri.hri import HRIListener

import cv2
from cv_bridge import CvBridge

import numpy as np

from PIL import ImageFont, ImageDraw
from PIL import Image as PILImage

from threading import Lock

import hashlib

rospack = RosPack()

# Drawing parameters definition
PASTEL_YELLOW = (174, 239, 238)
TEXT_BLACK = (0, 0, 0, 255)
BOX_THICKNESS = 3
THICKNESS_CORNERS = 2
LABEL_DISTANCE = 50
LABEL_WIDTH = 80
LABEL_HEIGHT = 30
SPACE_PER_CHARACTER = 14
LABEL_LINE_THICKNESS = 1
JOINT_RADIUS = 15
JOINT_THICKNESS = -1
FONTS_FOLDER = rospack.get_path("hri_visualization")+"/fonts"
FONT = FONTS_FOLDER+"/Montserrat/Montserrat-SemiBold.ttf"
LARGEST_LETTER = "M"
VIS_CORNER_GAP_RATIO = 0.1
VIS_CORNER_WIDTH_RATIO = 0.1
VIS_CORNER_HEIGHT_RATIO = 0.1

# 2D skeleton joints
# related to face keypoints won't be drawn
joints_to_draw = [
    Skeleton2D.NECK,
    Skeleton2D.RIGHT_SHOULDER,
    Skeleton2D.RIGHT_ELBOW,
    Skeleton2D.RIGHT_WRIST,
    Skeleton2D.LEFT_SHOULDER,
    Skeleton2D.LEFT_ELBOW,
    Skeleton2D.LEFT_WRIST,
    Skeleton2D.RIGHT_HIP,
    Skeleton2D.RIGHT_KNEE,
    Skeleton2D.RIGHT_ANKLE,
    Skeleton2D.LEFT_HIP,
    Skeleton2D.LEFT_KNEE,
    Skeleton2D.LEFT_ANKLE,
]

iconic_pokemons = ['Pikachu',
                  'Charizard',
                  'Mewtwo',
                  'Blastoise',
                  'Snorlax',
                  'Bulbasaur',
                  'Gyarados',
                  'Dragonite',
                  'Eevee',
                  'Lapras']

adjectives = ['Vegan',
              'Fiery',
              'Powerful',
              'Bright',
              'Sleepy',
              'Brave',
              'Fierce',
              'Clever',
              'Adaptable',
              'Gentle']

class HRIVisualizer:
    """ A class managing publishing an
        image stream where information
        regarding the detected people
        is displayed
    """
    class PersonDescriptor:
        """ Internal class used to describe
            person-related aspects
        """
        id_to_display = None
        label_width = None
        font = None
        max_distance_corner = None

    def __init__(self, funny_names, compressed_output):
        """ Constructor """
        self.font = self.calibrate_font_size(5)

        self.funny_names = funny_names

        self.hri_listener = HRIListener()
       
        self.body_sub = rospy.Subscriber(
            "/humans/bodies/tracked", IdsList, self.body_cb, queue_size=1
        )

        self.img_cb = rospy.Subscriber("/image", Image, self.img_cb, queue_size=1)

        self.compressed_output = compressed_output

        remappings = rospy.names.get_mappings()
        remapped_topic = remappings.get("/image", "/image_raw")
        if remapped_topic.endswith("/image_raw"):
            fixed_name_length = len(remapped_topic) - len("image_raw")
            hri_overlay_topic = remapped_topic[:fixed_name_length] + "hri_overlay"
        else:
            hri_overlay_topic = remapped_topic + "/hri_overlay"

        if compressed_output:
            self.img_pub = rospy.Publisher(
                hri_overlay_topic + "/compressed", CompressedImage, queue_size=1
            )
        else:
            self.img_pub = rospy.Publisher(hri_overlay_topic, Image, queue_size=1)

        self.bridge = CvBridge()

        self.faces = {}
        self.bodies = {}
        self.persons = {}

        self.persons_lock = Lock()

    def body_cb(self, msg):
        """ Callback storing information regarding the
            detected bodies
        """
        for id in msg.ids:
            if not id in list(self.bodies):
                skeleton_topic = "/humans/bodies/" + id + "/skeleton2d"
                self.bodies[id] = [
                    rospy.Subscriber(
                        skeleton_topic,
                        Skeleton2D,
                        self.skeleton_cb,
                        (id),
                        queue_size=1
                    ),
                    None,
                ]

        for id in list(self.bodies):
            if not id in msg.ids:
                self.bodies[id][0].unregister()
                del self.bodies[id]

    def skeleton_cb(self, skeleton_msg, args):
        """ Callback storing information regarding
            a body's skeleton coordinates
        """
        id = args
        self.bodies[id][1] = skeleton_msg.skeleton

    def generate_funny_ids(self, person_id):
        """ Extracting a funny id, which is a combination
            of an adjective and a name from two 
            predefined lists
        """
        person_id_reverse = person_id[::-1]
        hash_value_adjective = hashlib.md5(person_id.encode('utf-8')).hexdigest()
        hash_value_name = hashlib.md5(person_id_reverse.encode('utf-8')).hexdigest()
        random_adjective_index = int(hash_value_adjective, 16)%len(adjectives)
        random_name_index = int(hash_value_name, 16)%len(iconic_pokemons)
        return adjectives[random_adjective_index] \
               +" " \
               +iconic_pokemons[random_name_index]

    def img_cb(self, msg):
        """ Callback managing the incoming images.
            It draws the bounding boxes for the
            detected faces and the skeletons
            for the detected bodies
        """
        if not self.persons_lock.locked():
            with self.persons_lock:
                # updating the tracked persons
                tracked_persons = self.hri_listener.tracked_persons 
                for person in tracked_persons:
                    if person not in self.persons:
                        self.persons[person] = self.PersonDescriptor()
                        if self.funny_names:
                            id_displayed = self.generate_funny_ids(person)
                        else:
                            id_displayed = person
                        self.persons[person].id_to_display = id_displayed
                        self.persons[person].label_width = SPACE_PER_CHARACTER*len(id_displayed)
                        self.persons[person].font = self.calibrate_font_size(len(id_displayed))
                        
                for person in list(self.persons.keys()):
                    if not person in tracked_persons:
                        del self.persons[person]

                img = self.bridge.imgmsg_to_cv2(msg, "bgr8")
                (height, width, _) = img.shape
                for person in list(self.persons):
                    face = tracked_persons[person].face
                    if face and face.roi:
                        # Label sizing calibration
                        label_width = self.persons[person].label_width
                        font = self.persons[person].font

                        starting_point = (
                            face.roi.x,
                            face.roi.y
                        )
                        ending_point = (
                            face.roi.x+face.roi.width,
                            face.roi.y+face.roi.height,
                        )
                        img = cv2.rectangle(
                            img,
                            starting_point,
                            ending_point,
                            PASTEL_YELLOW,
                            BOX_THICKNESS,
                            lineType=cv2.LINE_AA,
                        )

                        # sizing the height/width of the localisation corners
                        visual_roi_x = face.roi.x + BOX_THICKNESS
                        visual_roi_y = face.roi.y + BOX_THICKNESS
                        visual_roi_width = face.roi.width - (2*BOX_THICKNESS)
                        visual_roi_height = face.roi.height - (2*BOX_THICKNESS)

                        ptsTopLeft = np.array(
                            [
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height \
                                    + VIS_CORNER_HEIGHT_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width
                                    + VIS_CORNER_WIDTH_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                            ],
                            dtype=np.int32,
                        )
                        ptsBottomLeft = np.array(
                            [
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height \
                                    - VIS_CORNER_HEIGHT_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_width \
                                    + VIS_CORNER_WIDTH_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                            ],
                            dtype=np.int32,
                        )
                        ptsTopRight = np.array(
                            [
                                [
                                    visual_roi_x \
                                    + visual_roi_width\
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width \
                                    - VIS_CORNER_WIDTH_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + visual_roi_width \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + visual_roi_width \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + VIS_CORNER_GAP_RATIO*visual_roi_height \
                                    + VIS_CORNER_HEIGHT_RATIO*visual_roi_height
                                ],
                            ],
                            dtype=np.int32,
                        )
                        ptsBottomRight = np.array(
                            [
                                [
                                    visual_roi_x \
                                    + visual_roi_width\
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width \
                                    - VIS_CORNER_WIDTH_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + visual_roi_width\
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height
                                ],
                                [
                                    visual_roi_x \
                                    + visual_roi_width\
                                    - VIS_CORNER_GAP_RATIO*visual_roi_width,
                                    visual_roi_y \
                                    + visual_roi_height \
                                    - VIS_CORNER_GAP_RATIO*visual_roi_height \
                                    - VIS_CORNER_HEIGHT_RATIO*visual_roi_height
                                ],
                            ],
                            dtype=np.int32,
                        )

                        img = cv2.polylines(
                            img,
                            [ptsTopLeft, ptsBottomLeft, ptsBottomRight, ptsTopRight],
                            isClosed=False,
                            color=PASTEL_YELLOW,
                            thickness=THICKNESS_CORNERS,
                            lineType=cv2.LINE_AA,
                        )

                        # Now inserting the label.
                        # Step 1: checking if a label point already exists.
                        # If this is not the case, selecting the further point
                        # the corners of the image.
                        if not self.persons[person].max_distance_corner:
                            further_corner = self.find_max_distance_corner(
                                face.roi.x + face.roi.width / 2,
                                face.roi.y + face.roi.height / 2,
                                msg.width,
                                msg.height,
                            )
                            self.persons[person].max_distance_corner = [
                                further_corner[0] * msg.width,
                                further_corner[1] * msg.height,
                            ]

                        # Step 2: if the corner has already been computed,
                        # it will remain the same as long as the label would
                        # be outside of the image.
                        roi_corner = np.array(
                            [
                                face.roi.x + (self.persons[person].max_distance_corner[0] / msg.width * face.roi.width),
                                face.roi.y + (self.persons[person].max_distance_corner[1] / msg.height * face.roi.height),
                            ]
                        )
                        label_to_corner = np.array(self.persons[person].max_distance_corner) - roi_corner
                        label_to_corner_distance = np.linalg.norm([roi_corner[0] \
                                                                   - self.persons[person].max_distance_corner[0],
                                                                   roi_corner[1] \
                                                                   - self.persons[person].max_distance_corner[1]],
                                                                  2)
                        label_corner = (
                            roi_corner
                            + (label_to_corner / label_to_corner_distance)
                            * LABEL_DISTANCE
                        )
                        if (
                            label_to_corner_distance
                            < (LABEL_DISTANCE + np.sqrt(label_width ** 2 + LABEL_HEIGHT ** 2))
                            or (label_corner[0] - label_width < 0)
                            or (label_corner[0] + label_width > msg.width)
                            or (label_corner[1] - LABEL_HEIGHT < 0)
                            or (label_corner[1] + LABEL_HEIGHT > msg.height)
                        ):
                            further_corner = self.find_max_distance_corner(
                                face.roi.x + face.roi.width / 2,
                                face.roi.y + face.roi.height / 2,
                                msg.width,
                                msg.height,
                            )
                            self.persons[person].max_distance_corner = [
                                further_corner[0] * msg.width,
                                further_corner[1] * msg.height,
                            ]
                            roi_corner = np.array(
                                [
                                    face.roi.x + (self.persons[person].max_distance_corner[0] / msg.width * face.roi.width),
                                    face.roi.y + (self.persons[person].max_distance_corner[1] / msg.height * face.roi.height),
                                ]
                            )
                            label_to_corner = np.array(self.persons[person].max_distance_corner) - roi_corner
                            label_corner = (
                                roi_corner
                                + (label_to_corner / np.linalg.norm(label_to_corner, 2))
                                * LABEL_DISTANCE
                            )

                        # Step 3: at this point the face
                        # should have assigned a far-enough
                        # corner point. It's time to print the label
                        roi_corner = np.array(roi_corner, dtype=int)
                        roi_corner = tuple(roi_corner)
                        label_corner = np.array(label_corner, dtype=int)
                        label_corner = tuple(label_corner)
                        img = cv2.line(
                            img,
                            roi_corner,
                            label_corner,
                            color=PASTEL_YELLOW,
                            thickness=LABEL_LINE_THICKNESS,
                            lineType=cv2.LINE_AA,
                        )
                        roi_corner_opposite = self.encode_opposite_corner(
                            self.persons[person].max_distance_corner[0], self.persons[person].max_distance_corner[1]
                        )
                        if roi_corner_opposite[0] == 0:
                            label_top_left_x = label_corner[0]
                            label_bottom_right_x = label_corner[0] + label_width
                        else:
                            label_top_left_x = label_corner[0] - label_width
                            label_bottom_right_x = label_corner[0]
                        if roi_corner_opposite[1] == 0:
                            label_top_left_y = label_corner[1]
                            label_bottom_right_y = label_corner[1] + LABEL_HEIGHT
                        else:
                            label_top_left_y = label_corner[1] - LABEL_HEIGHT
                            label_bottom_right_y = label_corner[1]

                        img = cv2.rectangle(
                            img,
                            (label_top_left_x, label_top_left_y),
                            (label_bottom_right_x, label_bottom_right_y),
                            PASTEL_YELLOW,
                            -1,
                            lineType=cv2.LINE_AA,
                        )
                        
                        text_width, text_height = font.getsize(self.persons[person].id_to_display)

                        text_top_left = [
                            label_top_left_x + (label_width - text_width) / 2,
                            label_top_left_y + (LABEL_HEIGHT - text_height) / 2,
                        ]
                        text_top_left = np.array(text_top_left, dtype=int)

                        rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                        pil_img = PILImage.fromarray(rgb_img)

                        draw = ImageDraw.Draw(pil_img)
                        if self.persons[person].id_to_display:
                            draw.text(text_top_left,
                                      self.persons[person].id_to_display,
                                      font=self.font,
                                      fill=TEXT_BLACK)
                        else:
                            draw.text(text_top_left,
                                      id,
                                      font=self.font,
                                      fill=TEXT_BLACK)

                        img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)

                for id in list(self.bodies):
                    skeleton = self.bodies[id][1]
                    if skeleton:
                        upper_chain = [
                            skeleton[Skeleton2D.RIGHT_WRIST],
                            skeleton[Skeleton2D.RIGHT_ELBOW],
                            skeleton[Skeleton2D.RIGHT_SHOULDER],
                            skeleton[Skeleton2D.NECK],
                            skeleton[Skeleton2D.LEFT_SHOULDER],
                            skeleton[Skeleton2D.LEFT_ELBOW],
                            skeleton[Skeleton2D.LEFT_WRIST],
                        ]

                        body = [
                            skeleton[Skeleton2D.LEFT_SHOULDER],
                            skeleton[Skeleton2D.LEFT_HIP],
                            skeleton[Skeleton2D.RIGHT_HIP],
                            skeleton[Skeleton2D.RIGHT_SHOULDER],
                        ]

                        left_leg = [
                            skeleton[Skeleton2D.LEFT_HIP],
                            skeleton[Skeleton2D.LEFT_KNEE],
                            skeleton[Skeleton2D.LEFT_ANKLE],
                        ]

                        right_leg = [
                            skeleton[Skeleton2D.RIGHT_HIP],
                            skeleton[Skeleton2D.RIGHT_KNEE],
                            skeleton[Skeleton2D.RIGHT_ANKLE],
                        ]

                        skeleton_lines_segments = [upper_chain, body, left_leg, right_leg]

                        for joint in joints_to_draw:
                            joint_x = int(skeleton[joint].x * width)
                            joint_y = int(skeleton[joint].y * height)
                            img = cv2.circle(
                                img, (joint_x, joint_y), JOINT_RADIUS, PASTEL_YELLOW, JOINT_THICKNESS
                            )

                        for idx, segment in enumerate(skeleton_lines_segments):
                            segment = [
                                (int(joint.x * width), int(joint.y * height))
                                for joint in segment
                            ]
                            segment = np.array(segment, dtype=np.int32)
                            skeleton_lines_segments[idx] = segment

                        img = cv2.polylines(
                            img,
                            skeleton_lines_segments,
                            isClosed=False,
                            color=PASTEL_YELLOW,
                            thickness=THICKNESS_CORNERS,
                            lineType=cv2.LINE_AA,
                        )

                if self.compressed_output:
                    img_msg = CompressedImage()
                    img_msg.header.stamp = rospy.Time.now()
                    img_msg.format = "jpeg"
                    img_msg.data = np.array(cv2.imencode(".jpg", img)[1]).tobytes()
                else:
                    img_msg = self.bridge.cv2_to_imgmsg(img, "bgr8")

                self.img_pub.publish(img_msg)


    def find_max_distance_corner(self, x, y, width, height):
        """ Function returning the maximum distance
            corner of the image. The result is encoded as:
                - [0, 0] = top left corner
                - [1, 0] = top right corner
                - [0, 1] = bottom left corner
                - [1, 1] = bottom right corner
        """
        return [x < width / 2, y < height / 2]

    def encode_opposite_corner(self, corner_x, corner_y):
        """ Following the same type of enconding
            described in the find_max_distance_corner,
            this function returns the opposite corner
        """
        return [int(not bool(corner_x)), int(not bool(corner_y))]

    def calibrate_font_size(self, number_of_letters):
        """ Initial calibration of the font size
            for the ids label. It uses PIL tools,
            not opencv tools
        """
        self.fontsize = 1
        label = LARGEST_LETTER * number_of_letters
        label_width = SPACE_PER_CHARACTER * number_of_letters
        font = ImageFont.truetype(FONT, self.fontsize)
        text_width, text_height = font.getsize(label)
        while text_width < (label_width - 10) and text_height < (LABEL_HEIGHT - 6):
            self.fontsize += 1
            font = ImageFont.truetype(FONT, self.fontsize)
            text_size, text_height = font.getsize(label)
        self.fontsize -= 2
        return ImageFont.truetype(FONT, self.fontsize)


if __name__ == "__main__":
    rospy.init_node("hri_visualization")

    funny_names = rospy.get_param("~funny_names", False)
    compressed_output = rospy.get_param("~compressed_output", False)

    visualizer = HRIVisualizer(funny_names, compressed_output)

    rospy.spin()
